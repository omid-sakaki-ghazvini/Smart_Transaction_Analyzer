import re
from datetime import datetime
import streamlit as st
import duckdb
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
import torch

# ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø§ÙˆÙ„ÛŒÙ‡
st.set_page_config(
    page_title="ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ù…Ø§Ù„ÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù¾ÛŒØ´Ø±ÙØªÙ‡",
    page_icon="ğŸ’³",
    layout="wide"
)

# --- Ù…Ø¯Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø²Ø¨Ø§Ù† Ø·Ø¨ÛŒØ¹ÛŒ ---
@st.cache_resource
def load_nlp_model():
    try:
        model_name = "HooshvareLab/bert-fa-base-uncased"
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(model_name)
        
        return pipeline(
            "text-classification",
            model=model,
            tokenizer=tokenizer,
            device=0 if torch.cuda.is_available() else -1
        )
    except Exception as e:
        st.error(f"Ø®Ø·Ø§ Ø¯Ø± Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„: {str(e)}")
        return None

nlp_pipe = load_nlp_model()

# --- Ù¾Ø§ÛŒÚ¯Ø§Ù‡ Ø¯Ø§Ø¯Ù‡ ---
def init_db():
    conn = duckdb.connect(database=':memory:')
    conn.execute("""
    CREATE TABLE IF NOT EXISTS transactions (
        id INTEGER PRIMARY KEY,
        date DATE,
        amount DECIMAL(12, 2),
        category VARCHAR(50),
        description TEXT
    )""")
    
    # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ù†Ù…ÙˆÙ†Ù‡
    sample_data = [
        (1, '2023-01-15', 150000, 'ØºØ°Ø§', 'Ø±Ø³ØªÙˆØ±Ø§Ù†'),
        (2, '2023-01-20', 250000, 'Ø­Ù…Ù„ Ùˆ Ù†Ù‚Ù„', 'ØªØ§Ú©Ø³ÛŒ'),
        (3, '2023-02-05', 3000000, 'Ù…Ø³Ú©Ù†', 'Ø§Ø¬Ø§Ø±Ù‡'),
        (4, '2023-02-15', 500000, 'ØºØ°Ø§', 'Ø³ÙØ§Ø±Ø´ ØºØ°Ø§'),
        (5, '2023-03-01', 1000000, 'ØªÙØ±ÛŒØ­', 'Ø³ÛŒÙ†Ù…Ø§')
    ]
    
    for data in sample_data:
        conn.execute("INSERT OR IGNORE INTO transactions VALUES (?, ?, ?, ?, ?)", data)
    
    return conn

if 'db' not in st.session_state:
    st.session_state.db = init_db()

# --- ØªÙˆØ§Ø¨Ø¹ Ú©Ù…Ú©ÛŒ ---
def extract_dates(query):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØ§Ø±ÛŒØ® Ø§Ø² Ù…ØªÙ† Ø¨Ø§ Ø§Ø³ØªÙØ§Ø¯Ù‡ Ø§Ø² regex"""
    date_patterns = [
        (r"\d{4}-\d{2}-\d{2}", "%Y-%m-%d"),  # ÙØ±Ù…Øª Ø§Ø³ØªØ§Ù†Ø¯Ø§Ø±Ø¯
        (r"\d{2}/\d{2}/\d{4}", "%d/%m/%Y"),  # ÙØ±Ù…Øª Ø§ÛŒØ±Ø§Ù†ÛŒ
        (r"\d{4}/\d{2}/\d{2}", "%Y/%m/%d")   # ÙØ±Ù…Øª Ø¬Ø§ÛŒÚ¯Ø²ÛŒÙ†
    ]
    
    dates = []
    for pattern, date_format in date_patterns:
        matches = re.findall(pattern, query)
        for match in matches:
            try:
                dates.append(datetime.strptime(match, date_format).date())
            except:
                continue
    
    return sorted(dates) if dates else None

def get_category_from_query(query):
    """ØªØ´Ø®ÛŒØµ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ Ø§Ø² Ù…ØªÙ† Ø¨Ø§ ØªØ±Ú©ÛŒØ¨ NLP Ùˆ Ù‚ÙˆØ§Ù†ÛŒÙ†"""
    # ØªØ­Ù„ÛŒÙ„ Ø¨Ø§ Ù…Ø¯Ù„ NLP
    nlp_result = nlp_pipe(query)[0]['label'] if nlp_pipe else None
    
    # Ù‚ÙˆØ§Ù†ÛŒÙ† Ø¯Ø³ØªÛŒ Ø¨Ø±Ø§ÛŒ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ
    category_rules = {
        'ØºØ°Ø§': ['ØºØ°Ø§', 'Ø±Ø³ØªÙˆØ±Ø§Ù†', 'Ø³ÙØ§Ø±Ø´', 'Ù¾ÛŒØªØ²Ø§', 'Ú©Ø§ÙÙ‡'],
        'Ø­Ù…Ù„ Ùˆ Ù†Ù‚Ù„': ['ØªØ§Ú©Ø³ÛŒ', 'Ø§ØªÙˆØ¨ÙˆØ³', 'Ù…ØªØ±Ùˆ', 'Ø­Ù…Ù„', 'Ù†Ù‚Ù„'],
        'Ù…Ø³Ú©Ù†': ['Ù…Ø³Ú©Ù†', 'Ø§Ø¬Ø§Ø±Ù‡', 'Ø®ÙˆÙ†Ù‡', 'Ø®Ø§Ù†Ù‡', 'Ø¢Ù¾Ø§Ø±ØªÙ…Ø§Ù†'],
        'ØªÙØ±ÛŒØ­': ['ØªÙØ±ÛŒØ­', 'Ø³ÛŒÙ†Ù…Ø§', 'Ù¾Ø§Ø±Ú©', 'Ú¯Ø±Ø¯Ø´', 'Ù…Ø³Ø§ÙØ±Øª']
    }
    
    query_lower = query.lower()
    for category, keywords in category_rules.items():
        if any(keyword in query_lower for keyword in keywords):
            return category
    
    return nlp_result if nlp_result else None

# --- ØªÙˆØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ ---
def add_transaction(date, amount, category, description):
    try:
        st.session_state.db.execute("""
        INSERT INTO transactions VALUES (
            (SELECT COALESCE(MAX(id), 0) + 1 FROM transactions),
            ?, ?, ?, ?
        )""", [str(date), float(amount), category, description])
        return True
    except Exception as e:
        st.error(f"Ø®Ø·Ø§: {str(e)}")
        return False

def hybrid_nlp_to_sql(query):
    """ØªØ±Ú©ÛŒØ¨ NLP Ø¨Ø§ Ù‚ÙˆØ§Ù†ÛŒÙ† Ø¯Ø³ØªÛŒ Ø¨Ø±Ø§ÛŒ ØªØ¨Ø¯ÛŒÙ„ Ù¾Ø±Ø³â€ŒÙˆØ¬Ùˆ Ø¨Ù‡ SQL"""
    try:
        # Ù¾ÛŒØ´â€ŒÙ¾Ø±Ø¯Ø§Ø²Ø´ Ù¾Ø±Ø³â€ŒÙˆØ¬Ùˆ
        query = query.strip().lower()
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªØ§Ø±ÛŒØ®â€ŒÙ‡Ø§ (Ø§Ú¯Ø± ÙˆØ¬ÙˆØ¯ Ø¯Ø§Ø´ØªÙ‡ Ø¨Ø§Ø´Ù†Ø¯)
        dates = extract_dates(query)
        
        # ØªØ´Ø®ÛŒØµ Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ
        category = get_category_from_query(query)
        
        # Ø§Ù„Ú¯ÙˆÙ‡Ø§ÛŒ ØªØ±Ú©ÛŒØ¨ÛŒ
        if dates and len(dates) >= 2:
            # Ù¾Ø±Ø³â€ŒÙˆØ¬ÙˆÙ‡Ø§ÛŒ Ù…Ø­Ø¯ÙˆØ¯Ù‡ ØªØ§Ø±ÛŒØ®ÛŒ
            sql = f"""
            SELECT * FROM transactions 
            WHERE date BETWEEN '{dates[0]}' AND '{dates[1]}'
            ORDER BY date
            """
        elif "Ú†Ù†Ø¯ ØªØ§" in query or "ØªØ¹Ø¯Ø§Ø¯" in query:
            # Ù¾Ø±Ø³â€ŒÙˆØ¬ÙˆÙ‡Ø§ÛŒ Ø´Ù…Ø§Ø±Ø´ÛŒ
            if category:
                sql = f"SELECT COUNT(*) AS count FROM transactions WHERE category='{category}'"
            else:
                sql = "SELECT COUNT(*) AS count FROM transactions"
        elif "Ù…ÛŒØ§Ù†Ú¯ÛŒÙ†" in query or "Ù…ØªÙˆØ³Ø·" in query:
            # Ù¾Ø±Ø³â€ŒÙˆØ¬ÙˆÙ‡Ø§ÛŒ Ù…Ø­Ø§Ø³Ø¨Ø§ØªÛŒ
            if category:
                sql = f"SELECT AVG(amount) AS average FROM transactions WHERE category='{category}'"
            else:
                sql = "SELECT AVG(amount) AS average FROM transactions"
        elif category:
            # Ù¾Ø±Ø³â€ŒÙˆØ¬ÙˆÙ‡Ø§ÛŒ Ù…Ø¨ØªÙ†ÛŒ Ø¨Ø± Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ
            sql = f"""
            SELECT date, amount, description 
            FROM transactions 
            WHERE category='{category}'
            ORDER BY date DESC
            """
        elif "Ø¢Ø®Ø±ÛŒÙ†" in query or "Ø§Ø®ÛŒØ±" in query:
            # Ù¾Ø±Ø³â€ŒÙˆØ¬ÙˆÙ‡Ø§ÛŒ ØªØ±Ø§Ú©Ù†Ø´â€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ±
            sql = "SELECT * FROM transactions ORDER BY date DESC LIMIT 5"
        elif "Ø¯Ø³ØªÙ‡" in query or "Ú¯Ø±ÙˆÙ‡" in query or "Ø·Ø¨Ù‚Ù‡" in query:
            # Ù¾Ø±Ø³â€ŒÙˆØ¬ÙˆÙ‡Ø§ÛŒ Ú¯Ø±ÙˆÙ‡â€ŒØ¨Ù†Ø¯ÛŒ
            sql = """
            SELECT category, SUM(amount) AS total, COUNT(*) AS count
            FROM transactions 
            GROUP BY category 
            ORDER BY total DESC
            """
        else:
            # Ù¾ÛŒØ´â€ŒÙØ±Ø¶ - Ø¬Ù…Ø¹ Ú©Ù„
            sql = "SELECT SUM(amount) AS total FROM transactions"
        
        # Ø§Ø¬Ø±Ø§ÛŒ Ú©ÙˆØ¦Ø±ÛŒ
        df = st.session_state.db.execute(sql).fetchdf()
        return df, sql
        
    except Exception as e:
        return None, f"Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù¾Ø±Ø³â€ŒÙˆØ¬Ùˆ: {str(e)}"

# --- Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ ---
st.title("ğŸ’³ ØªØ­Ù„ÛŒÙ„Ú¯Ø± Ù‡ÙˆØ´Ù…Ù†Ø¯ Ù…Ø§Ù„ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡")

tab1, tab2, tab3 = st.tabs(["Ø«Ø¨Øª ØªØ±Ø§Ú©Ù†Ø´", "ØªØ­Ù„ÛŒÙ„ Ø³Ù†ØªÛŒ", "Ù¾Ø±Ø³â€ŒÙˆØ¬ÙˆÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯"])

with tab1:
    st.header("Ø«Ø¨Øª ØªØ±Ø§Ú©Ù†Ø´ Ø¬Ø¯ÛŒØ¯")
    with st.form("transaction_form"):
        col1, col2 = st.columns(2)
        with col1:
            date = st.date_input("ØªØ§Ø±ÛŒØ®", datetime.now())
            amount = st.number_input("Ù…Ø¨Ù„Øº (Ø±ÛŒØ§Ù„)", min_value=1000, step=1000)
        with col2:
            category = st.selectbox(
                "Ø¯Ø³ØªÙ‡â€ŒØ¨Ù†Ø¯ÛŒ",
                ["ØºØ°Ø§", "Ø­Ù…Ù„ Ùˆ Ù†Ù‚Ù„", "Ù…Ø³Ú©Ù†", "ØªÙØ±ÛŒØ­", "Ø®Ø±ÛŒØ¯", "Ø³Ø§ÛŒØ±"]
            )
            description = st.text_input("ØªÙˆØ¶ÛŒØ­Ø§Øª (Ø§Ø®ØªÛŒØ§Ø±ÛŒ)")
        
        submitted = st.form_submit_button("Ø«Ø¨Øª ØªØ±Ø§Ú©Ù†Ø´")
        if submitted:
            if add_transaction(date, amount, category, description):
                st.success("ØªØ±Ø§Ú©Ù†Ø´ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª Ø«Ø¨Øª Ø´Ø¯")

with tab2:
    st.header("ØªØ­Ù„ÛŒÙ„ Ø³Ù†ØªÛŒ")
    analysis_type = st.selectbox(
        "Ù†ÙˆØ¹ ØªØ­Ù„ÛŒÙ„",
        ["Ú©Ù„ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§", "ØªÙˆØ²ÛŒØ¹ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§", "ØªØ±Ø§Ú©Ù†Ø´â€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ±", "Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§"]
    )
    
    if analysis_type == "Ú©Ù„ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§":
        df = st.session_state.db.execute("SELECT SUM(amount) AS 'Ù…Ø¬Ù…ÙˆØ¹ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§' FROM transactions").fetchdf()
        st.dataframe(df, hide_index=True)
        
    elif analysis_type == "ØªÙˆØ²ÛŒØ¹ Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§":
        df = st.session_state.db.execute("""
        SELECT 
            category AS 'Ø¯Ø³ØªÙ‡', 
            SUM(amount) AS 'Ù…Ø¨Ù„Øº',
            ROUND(SUM(amount)*100/(SELECT SUM(amount) FROM transactions), 1) AS 'Ø¯Ø±ØµØ¯'
        FROM transactions 
        GROUP BY category 
        ORDER BY SUM(amount) DESC
        """).fetchdf()
        st.dataframe(df, hide_index=True)
        st.bar_chart(df.set_index('Ø¯Ø³ØªÙ‡')['Ù…Ø¨Ù„Øº'])
        
    elif analysis_type == "ØªØ±Ø§Ú©Ù†Ø´â€ŒÙ‡Ø§ÛŒ Ø§Ø®ÛŒØ±":
        df = st.session_state.db.execute("SELECT * FROM transactions ORDER BY date DESC LIMIT 10").fetchdf()
        st.dataframe(df, hide_index=True)
        
    elif analysis_type == "Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§":
        df = st.session_state.db.execute("SELECT AVG(amount) AS 'Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ù‡Ø²ÛŒÙ†Ù‡â€ŒÙ‡Ø§' FROM transactions").fetchdf()
        st.dataframe(df, hide_index=True)

with tab3:
    st.header("Ù¾Ø±Ø³â€ŒÙˆØ¬ÙˆÛŒ Ù‡ÙˆØ´Ù…Ù†Ø¯ (NLP)")
    
    user_query = st.text_input("Ø³ÙˆØ§Ù„ Ø®ÙˆØ¯ Ø±Ø§ Ø¨Ù‡ Ø²Ø¨Ø§Ù† ÙØ§Ø±Ø³ÛŒ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯:", key="query_input")
    
    if st.button("Ø§Ø¬Ø±Ø§ÛŒ Ù¾Ø±Ø³â€ŒÙˆØ¬Ùˆ") and user_query:
        with st.spinner("Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø³ÙˆØ§Ù„..."):
            result, sql = hybrid_nlp_to_sql(user_query)
            
            if result is not None:
                st.success("Ù†ØªØ§ÛŒØ¬ Ù¾Ø±Ø³â€ŒÙˆØ¬Ùˆ:")
                st.dataframe(result)
                
                with st.expander("Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ú©ÙˆØ¦Ø±ÛŒ SQL ØªÙˆÙ„ÛŒØ¯ Ø´Ø¯Ù‡"):
                    st.code(sql, language='sql')
            else:
                st.error(sql)


st.markdown("<br><hr><center>Made with â¤ï¸ by <a href='https://omidsakaki.ir/'><strong>omid sakaki ghazvini</strong></a></center><hr>", unsafe_allow_html=True)
